{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 1: Introduction à PyTorch\n",
    "\n",
    "Le but de se laboratoire est de se familiariser avec PyTorch en l'utilisant pour faire du classement sur deux jeux de données connus: MNIST et CIFAR-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from deeplib.datasets import load_mnist, load_cifar10\n",
    "from sklearn.metrics import accuracy_score\n",
    "from deeplib.net import MnistNet, CifarNet\n",
    "from deeplib.history import History\n",
    "from deeplib.visualization import plot_images\n",
    "from deeplib.datasets import train_valid_loaders\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SequentialSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist\n",
    "\n",
    "Mnist est jeu de données contenant des images de chiffres manuscrits.<br>\n",
    "Le jeu de données est séparé comme suit: 50000 images sont utilisées en entraînement et 10000 en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist, mnist_test = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du jeu de données\n",
    "\n",
    "Exécuter cette cellule plusieurs fois pour visualiser les données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "idx = random.sample([x for x in range(len(mnist))], 9)\n",
    "images = [np.array(mnist[i][0]) for i in idx]\n",
    "targets = [mnist[i][1] for i in idx]\n",
    "\n",
    "plot_images(images, targets, gray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'entraînement, nous avons besoin d'une fonction ``train`` pour entraîner le réseau et d'une fonction ``validate`` pour estimer la performance de notre modèle.\n",
    "\n",
    "Pour chaque epoch, la fonction ``train`` passe au travers de toutes les images du jeu de données dans un ordre aléatoire et met à jour les poids du réseau selon la perte calculée.<br>\n",
    "Pour entraîner le réseau, la fonction doit recevoir 3 hyperparamètres: \n",
    "1. le nombre d'epochs qui indique combien de fois toutes les images du jeu de données seront visualisées \n",
    "2. la taille de la batch qui indique combien d'images seront traitées à la fois\n",
    "3. le taux d'apprentissage qui détermine la vitesse à laquelle chaque poids du réseau sera modifié\n",
    "\n",
    "Pendant l'entraînement, une partie des données est utilisée pour créer un ensemble de validation qui permet d'estimer les performances de généralisation du modèle.\n",
    "\n",
    "Finalement, on sauvegarde aussi quelques informations importantes afin de visualiser ce qui se passe pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, dataset, n_epoch, batch_size, learning_rate, use_gpu=False):\n",
    "    history = History()\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    dataset.transform = ToTensor()\n",
    "    train_loader, val_loader = train_valid_loaders(dataset, batch_size=batch_size)\n",
    "\n",
    "    for i in range(n_epoch):\n",
    "        model.train()\n",
    "        for j, batch in enumerate(train_loader):\n",
    "            \n",
    "            inputs, targets = batch\n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                targets = targets.cuda()\n",
    "                \n",
    "            inputs = Variable(inputs)\n",
    "            targets = Variable(targets)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(inputs)\n",
    "\n",
    "            loss = criterion(output, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_acc, train_loss = validate(model, train_loader, use_gpu)\n",
    "        val_acc, val_loss = validate(model, val_loader, use_gpu)\n",
    "        history.save(train_acc, val_acc, train_loss, val_loss)\n",
    "        print('Epoch {} - Train acc: {:.2f} - Val acc: {:.2f} - Train loss: {:.4f} - Val loss: {:.4f}'.format(i, train_acc, val_acc, train_loss, val_loss))\n",
    "        \n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Pour chaque image du jeu de donnée, la fonction ``validate`` fait prédire une classe au réseau entraîné et compare le résultat avec la vraie réponse. Elle retourne le pourcentage de réponse correcte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate(model, val_loader, use_gpu=False):\n",
    "    true =[]\n",
    "    pred = []\n",
    "    val_loss = []\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    \n",
    "    for j, batch in enumerate(val_loader):\n",
    "        \n",
    "        inputs, targets = batch\n",
    "        if use_gpu:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            \n",
    "        inputs = Variable(inputs, volatile=True)\n",
    "        targets = Variable(targets, volatile=True)\n",
    "        output = model(inputs)\n",
    "        \n",
    "        predictions = output.max(dim=1)[1]\n",
    "        \n",
    "        val_loss.append(criterion(output, targets).data[0])\n",
    "        true.extend(targets.data.cpu().numpy().tolist())\n",
    "        pred.extend(predictions.data.cpu().numpy().tolist())\n",
    "\n",
    "    return accuracy_score(true, pred) * 100, sum(val_loss) / len(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînons un modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MnistNet()\n",
    "\n",
    "n_epoch = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "history = train(model, mnist, n_epoch, batch_size, learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante permet de visualiser l'entraînement précédent.\n",
    "\n",
    "Le premier graphique montre l'évolution de la précision du modèle sur le jeu de données d'entraînement et sur celui de validation. Le deuxième montre la perte sur les deux jeux de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalement, évaluons les performances du modèle sur le jeu de données de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mnist_test.transform = ToTensor()\n",
    "sampler = SequentialSampler(mnist_test)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "score, loss = validate(model, test_loader)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Différences CPU - GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour faire exécuter le code sur GPU, il faut déplacer le model, les inputs et les targets sur le GPU. \n",
    "\n",
    "Le réseau contient deux couches de convolutions qui servent à extraire des caractéristiques des images tandis que les couches linéaires servent de classifieur. Il s'agit d'un pipeline commun pour toutes les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_gpu = MnistNet()\n",
    "model_gpu.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparons le temps d'exécution sur CPU et sur GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 256\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendant l'entraînement, vérifier l'utilisation du CPU avec la commande ``top``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training on CPU')\n",
    "model = MnistNet()\n",
    "\n",
    "start_cpu = time.time()\n",
    "history = train(model, mnist, epoch, batch_size, lr)\n",
    "end_cpu = time.time()\n",
    "\n",
    "cpu_time = end_cpu - start_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour vous assurer que le réseau entraîne bien sur GPU, utiliser la commande \n",
    "\n",
    "``watch -n 1 nvidia-smi`` \n",
    "\n",
    "Observer l'utilisation de la carte et la quantité de mémoire utilisée pendant l'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Training on GPU')\n",
    "model_gpu = MnistNet()\n",
    "model_gpu.cuda()\n",
    "\n",
    "start_gpu = time.time()\n",
    "history_gpu = train(model_gpu, mnist, epoch, batch_size, lr, use_gpu=True)\n",
    "end_gpu = time.time()\n",
    "\n",
    "gpu_time = end_gpu - start_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('CPU - Training time: {:.2f}s'.format(cpu_time))\n",
    "print('GPU - Training time: {:.2f}s'.format(gpu_time))\n",
    "print('Ratio: {:.2f}x'.format((cpu_time) / (gpu_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR 10\n",
    "\n",
    "CIFAR-10 est un jeu de données comportant des images séparés en 10 classe:<br>\n",
    "0 - Avion<br>\n",
    "1 - Voiture<br>\n",
    "2 - Oiseau<br>\n",
    "3 - Chat<br>\n",
    "4 - Chevreuil<br>\n",
    "5 - Chien<br>\n",
    "6 - Grenouille<br>\n",
    "7 - Cheval<br>\n",
    "8 - Bateau<br>\n",
    "9 - Camion<br>\n",
    "\n",
    "Le jeu de données contient 50000 images d'entraînement. Nous en utiliserons 40000 pour l'entraînement et 10000 pour la validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisation du jeu de données\n",
    "\n",
    "Encore une fois, vous pouvez exécuter cette cellule plusieurs fois pour bien visualiser le jeu de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar, cifar_test = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_names = [\n",
    "    'airplane',\n",
    "    'automobile',\n",
    "    'bird',\n",
    "    'cat',\n",
    "    'deer',\n",
    "    'dog',\n",
    "    'frog',\n",
    "    'horse',\n",
    "    'ship',\n",
    "    'truck'\n",
    "]\n",
    "\n",
    "idx = random.sample([x for x in range(len(cifar))], 9)\n",
    "images = [np.array(cifar[i][0]) for i in idx]\n",
    "images = np.asarray(images)\n",
    "targets = [cifar[i][1] for i in idx]\n",
    "\n",
    "plot_images(images, targets, label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices\n",
    "\n",
    "Utilisez les 3 cellules suivantes pour répondre aux questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epoch = 5\n",
    "batch_size = 64\n",
    "learning_rate = 0.1\n",
    "\n",
    "model= CifarNet()\n",
    "model.cuda()\n",
    "\n",
    "history = train(model, cifar, epoch, batch_size, learning_rate, use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar_test.transform = ToTensor()\n",
    "sampler = SequentialSampler(cifar_test)\n",
    "test_loader = torch.utils.data.DataLoader(cifar_test, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "score, loss = validate(model, test_loader, use_gpu=True)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet du nombre d'epochs\n",
    "\n",
    "Modifiez le nombre d'epochs et observez les performances du réseau.\n",
    "\n",
    "Que se passe-t-il s'il est trop grand?<br> \n",
    "S'il est trop petit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet de la taille de la batch\n",
    "\n",
    "Modifiez la taille de la batch et observez l'utilisation de la carte graphique.\n",
    "\n",
    "Sur quoi est-ce que la taille de la batch semble avoir le plus d'impact?<br>\n",
    "Est-ce qu'elle impacte les performances?<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effet du taux d'apprentissage (lr)\n",
    "\n",
    "Finalement, observez l'impact du taux d'apprentissage sur l'entraînement.\n",
    "\n",
    "Que se passe-t-il s'il est trop grand?<br> \n",
    "S'il est trop petit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Défi\n",
    "\n",
    "Modifiez les hyperparamètres pour améliorer les performances du réseau.<br>\n",
    "Essayez d'obtenir plus de 65% en test.\n",
    "\n",
    "Vous pouvez aussi tenter de battre le state of the art: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glo4030-7030",
   "language": "python",
   "name": "glo4030-7030"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
